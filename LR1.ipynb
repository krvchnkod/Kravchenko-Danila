{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 1.\n",
    "### Вариант 1\n",
    "\n",
    "Работа выполнена студентом группы М1О-415Бки-19 Кравченко Д.В."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "dataset = pd.read_csv(\"datasets/breast_cancer.csv\")\n",
    "dataset = dataset.drop(columns = 'Unnamed: 32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Распределение величин\n",
    "Рассмотрим распределение параметров в зависимости от диагноза, где красным показан диагноз **М** (злокачественная опухоль), а синим - дигноз **B** (доброкачественная опухоль):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "width = 5\n",
    "height = 6\n",
    "\n",
    "fig, axs = plt.subplots(width, height, figsize=(25,20))\n",
    "\n",
    "for i in range(2,31):\n",
    "    x = (i - 2) % width\n",
    "    y = (i - 2) // width\n",
    "    series_b = dataset[dataset[\"diagnosis\"] == \"M\"][dataset.columns[i]]\n",
    "    series_m = dataset[dataset[\"diagnosis\"] == \"B\"][dataset.columns[i]]\n",
    "    axs[x, y].hist(series_b, color = 'blue', alpha = 0.8, density = True, stacked = True)\n",
    "    axs[x, y].hist(series_m, color = 'red', alpha = 0.8, density = True, stacked = True)\n",
    "    axs[x, y].set_title(dataset.columns[i])\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно по графикам, наиболее сильно с диагнозом коррелируют следующие параметры:\n",
    " - ```radius_mean```\n",
    " - ```radius_se```\n",
    " - ```radius_worst```\n",
    " - ```area_mean```\n",
    " - ```area_se```\n",
    " - ```area_worst```\n",
    " - ```compactness_mean```\n",
    " - ```concavity_mean```\n",
    " - ```concave_points_mean```\n",
    " - ```perimeter_worst```\n",
    "\n",
    "Проверим подробнее корреляцию между диагнозом и параметрами."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Корреляция\n",
    "Рассмотрим корреляцию между диагнозом и остальными параметрами. Для рассчета корреляции строковый параметр ```diagnosis``` необходимо преобразовать в тип категории, где ```0``` - означает диагноз **В**, а ```1``` - диагноз **М**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"diagnosis\"] = dataset[\"diagnosis\"].astype('category').cat.codes\n",
    "corr_matrix = dataset.loc[:,dataset.columns!='id'].corr(numeric_only=True)\n",
    "corr_matrix[\"diagnosis\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим зависимости между наиболее коррелирующими с диагнозом параметрами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "important_features = [column for column in dataset.columns if column not in ['id', 'diagnosis'] and abs(corr_matrix['diagnosis'][column]) > 0.5]\n",
    "scatter_matrix(dataset[important_features],figsize=(20,20));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить достаточно четкие зависимости между параметрами:\n",
    " - линейную зависимость между ```radius_mean``` и ```perimeter_mean```\n",
    " - линейную зависимость между ```radius_worst``` и ```perimeter_worst```\n",
    " - квадратичную зависимость между ```area_mean``` и ```radius_mean```/```perimeter_mean```\n",
    " - квадратичную зависимосит между ```area_worst``` и ```radius_worst```/```perimeter_worst```\n",
    "Также можно заметить множество линейных и квадратичных зависимостей между другими параметрами, однако эти зависимости выражены гораздо менее явно.\n",
    "\n",
    "Проверим коэффициенты корреляции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(corr_matrix[\"radius_mean\"][\"perimeter_mean\"], corr_matrix[\"radius_worst\"][\"perimeter_worst\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основании этого можно сделать вывод, что некоторые параметры являются избыточными.\n",
    "\n",
    "Рассмотрим зависимость между диагнозом и наиболее коррелирующими параметрами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = dataset[dataset[\"diagnosis\"] == 1].plot.scatter(x=\"concave points_worst\", y=\"perimeter_worst\", color=\"Red\", label=\"M\", alpha = 0.6)\n",
    "dataset[dataset[\"diagnosis\"] == 0].plot.scatter(x=\"concave points_worst\", y=\"perimeter_worst\", color=\"Blue\", label=\"B\", alpha = 0.6, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем из сипска параметров наиболее коррелирующие с диагнозом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unimportant_features = ['id', 'diagnosis', 'radius_worst', 'radius_mean']\n",
    "important_features = [column for column in dataset.columns if column not in unimportant_features and abs(corr_matrix['diagnosis'][column]) > 0.5]\n",
    "important_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание обучающей и тестовой выборок\n",
    "Разделим датасет на стратифицированные выборки. После избавимся от пропусков в тестовой выборке (если есть)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "seed = 1989\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\n",
    "\n",
    "for train_index, test_index in sss.split(dataset, dataset[\"diagnosis\"]):\n",
    "    train_set = dataset.loc[train_index]\n",
    "    test_set = dataset.loc[test_index]\n",
    "print(f\"Train set size:\\t{len(train_set)}\\nTest set size:\\t{len(test_set)}\")\n",
    "\n",
    "test_labels = test_set['diagnosis'].copy()\n",
    "test_data = test_set.drop(['id', 'diagnosis'], axis=1)\n",
    "\n",
    "init_size = len(train_set)\n",
    "labels = train_set['diagnosis'].copy()\n",
    "data = train_set.drop(['id', 'diagnosis'], axis=1)\n",
    "print(f'There are {init_size - len(data)} rows with empty fields among {init_size} rows.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поставленная задача относится к задачам классификации - на основании вводимых параметров решать, принадлежит ли пациент к классу с диагнозом **В** или **М**.\n",
    "Попробуем решить задачу несколькими способами.\n",
    "\n",
    "## Дерево решений\n",
    "В связи с элементом случайности, проведем несколько тестов и оценим статистику в целом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from scipy import stats\n",
    "scores = np.empty([100], dtype=float)\n",
    "for i in range(0,100):\n",
    "    tree_cls = tree.DecisionTreeClassifier()\n",
    "    tree_cls = tree_cls.fit(data, labels)\n",
    "\n",
    "    scores[i] = tree_cls.score(test_data, test_labels)\n",
    "stats.describe(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейный классификатор\n",
    "Путем приведения классов **В** и **М** к значениям {-1, 1} можно привести задачу классификации к задаче регрессии. В ```sklearn``` представлено несколько методов решения такой задачи - к примеру, аргумент ```lsqr``` решает задачу с использованием метода наименьших квадратов, а ```sag``` и ```saga``` используют стохастический градиентный спуск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "solvers = ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "scores = []\n",
    "for solver in solvers:\n",
    "    reg = linear_model.RidgeClassifier(solver=solver)\n",
    "    reg.fit(data, labels)\n",
    "    scores.append(reg.score(test_data, test_labels))\n",
    "for solver, score in zip(solvers, scores):\n",
    "    print(f'{solver:<10}: {score}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь оценим работу вышеперечисленных методов при откидывании избыточных параметров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_train_data = train_set.copy().drop(unimportant_features, axis = 1)\n",
    "reduced_train_labels = train_set['diagnosis']\n",
    "reduced_test_data = test_set.copy().drop(unimportant_features, axis = 1)\n",
    "reduced_test_labels = test_set['diagnosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from scipy import stats\n",
    "scores = np.empty([100], dtype=float)\n",
    "for i in range(0,100):\n",
    "    tree_cls = tree.DecisionTreeClassifier()\n",
    "    tree_cls = tree_cls.fit(reduced_train_data, reduced_train_labels)\n",
    "\n",
    "    scores[i] = tree_cls.score(reduced_test_data, reduced_test_labels)\n",
    "stats.describe(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейный классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "solvers = ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "scores = []\n",
    "for solver in solvers:\n",
    "    reg = linear_model.RidgeClassifier(solver=solver)\n",
    "    reg.fit(reduced_train_data, reduced_train_labels)\n",
    "    scores.append(reg.score(reduced_test_data, reduced_test_labels))\n",
    "for solver, score in zip(solvers, scores):\n",
    "    print(f'{solver:<10}: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно увидеть из результатов, максимальной точностью является значение в ```95.61403%```. Этот результат является достаточно низким, что скорее всего обусловлено достаточно малым размером датасета.\n",
    "Помимо этого в выборке есть некоторые параметры, которые можно посчитать избыточными, однако их удаление ведет к ощутимому падению точности."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c099fed5826d2f543afff393c7b0c8056152f1c1d03e75bfa92bb25a755f7ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
